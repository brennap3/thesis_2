\chapter[Datamining approaches to research in terrorism]{Datamining approaches to research in terrorism}
\chaptermark{datamining terrorism research}

To counter terrorism not only requires that governments to research new methods to collect and assemble intelligence but also to scrutinize it so as produce actionable insights. During the cold war much intelligence could be gained by utilizing a limited number of sources which were rich in information and analysis of such could gleam a large amount of understanding into an enemies effectiveness and competencies in different areas, their disposition and stratagem. Traditional methodologies used in intelligence gathering include \citep{tanner2014examining}:
\begin{enumerate}
\item HUMINT (human intelligence) is intelligence collected from actors on the ground. These can include specialist troops, intelligence operatives, captured combatants.
\item GEOINT (Geospatial intelligence) Geospatial analysis carried out by satellites, drones and dedicated spy planes.
\item MASINT (Measurement and signature intelligence).
\item SIGINT (Signal intelligence), this is the analysis of intercepted signals.
\item TECHINT (Technical intelligence), is intelligence gathered from the technical analysis of equipment.
\item FININT  (Financial intelligence) is the generation of intelligence from analysis of financial records.
\end{enumerate}
CYBINT/OSINT (Cyber intelligence and Open Source intelligence) \citep{csahinnew} is information gathered from the web or open source intelligence and would be considered a new form of intelligence. Automated data mining and data analysis can be applied to both old and new  intelligence methodologies but has been applied most notably to CYBINT and OSINT and has in-fact largely enabled these fields.
However for all methodologies data integration is important, enabling the analysis of disparate types of data such as text, audio, biometric information, technical plans and imagery.

\section{Terrorism informatics}

Terrorism informatics is the utilization of a number of different techniques for combining disparate data from different sources and analysis of the data to  provide insights to intelligence specialists \citep{chau2015intelligence}. This requires a number of methods and system sourced from a number different disciplines which include computer science, business informatics, statistics, machine learning, computational linguistics, social network analysis. The analysis needed to produce actionable insights is usually produced in two ways by either data analysis and data mining. A framework for data mining for counter terrorism  includes problem description, data gestation, data mining, model appraisal and illustrating the knowledge gained in a succinct form.

Datamining is the automated extraction of hidden patterns from databases \citep{shmueli2016data}. Established data mining approaches include supervised methods such as  classification, prediction, unsupervised methods such as association rules, cluster analysis and outlier detection. More recent developments for identification of patterns within data include entity extraction. This is used to analyse text imagery, audio recordings and has been utilized to automatically identify suspects, whereabouts, cars and personnel traits from police reports. Datamining began to seriously grab the attention of government in 2002 as a means to counter terrorism data mining efforts to the investigation had pre-empted September 11 by a number of years with the building of 'Able Danger' , a counter terrorist tool. 'Able Danger' \citep{keefe2006can} had identified a number of the 9/11 terrorists prior to the attacks but had failed to act on it \citep{lance2006triple}. This has been superseded by other network access tools such as the NSA's special access program which builds a social web from a suspect person, examining their links to people, through emails, phones, address and other information used to link people. This type of network based on links is one means to carry out social network analysis, another means of using network analysis to detect suspect behaviour is to use affiliation networks. These are networks of in which members of the network are connected by have common interests in common and has been shown to be effective in corporations detecting fraud.

Automated data analysis involves the automation of data analysis through the use of subject based queries or pattern based queries. Subject based queries start with a specific subject and expand out from this subject by finding entities linked to this person. These could be other people, places, vehicles, phone numbers, emails or activities. This type of analysis often referred to as link analysis \citep{berry1997data} and has not only been used for terrorism research but has found commercial usage within fraud investigation work in the financial sector particularly in banking and insurance. The benefit of using this approach is that it can be used to find leads to other person(s), places, vehicles, phone numbers or emails. Commercial based systems such as I2 \citep{i2Analyze2016} (which is also used by military, intelligence and law enforcement) is used within 
fraud prevention units to investigate fraudulent claims and financial transactions.

Pattern based query automated data analysis involves the use of a pattern or a predictive model to identify a particular type of behaviour in a dataset. Again this type of analysis has seen considerable adoption, Detica NetReveal \citep{oatley2011data} which is used for finding patterns of credit card fraud amongst other applications in the financial services.  

Before analysis of the data takes place the data must first be collated, the quality assessed and then if necessary be cleansed. At its simplest this process may involve removal of identical records, normalizing the data, removing unneeded data (not only because it may be unneeded but because it may be illegal to hold such data). Other typical tasks would be the consideration of missing data and how to allow for it (through imputation of missing values), regulation of data types. More advanced preprocessing would include integration of disparate data through extraction of metadata from the original data \citep{derosa2004data}. Examples of this would include extraction of  time and place from a temporal and geo-tagged photograph. Also the heterogeneous nature of data used in counter terrorism have necessitated the adoption of new types of database technology which allow for the storage and querying of heterogeneous data.  

Data stored in a NOSQL database does not require data to be cleansed to the extent it must be to be useful, when stored in a NOSQL database. NOSQL also allows the storage of more data and is extremely important were a lot of data is generated such as analysis of logs, sensor data (or large arrays of sensors in the case of IOT) or social media \citep{jeberson2015survey}.

\section{Datamining approaches for counter terrorism}

Due to the transnational nature of  modern terrorism, the emergence of internet to enable rapid communication and decentralized nature of these groups, automatic collection and analysis of data allows examining text for words or phrases synonymous with terrorism. Similarly  the Department of Homeland Security uses a similar system to carry out entity extraction for terrorist specific terms such as 'Sarin', 'Anthrax', and different types of improvised explosive devices. These systems if they work coupled with information from  financial details,social network information and geodesic data can give an investigator a much richer set of data to investigate and also give more context to alerts. This remains a huge challenge for intelligence services.In the 2013 Boston bombings 10 tb of data were generated within 24 hours of the crime by the FBI regarding the terrorist incident \citep{jeberson2015survey}.The data also came from a number of disparate sources including phone tower cell call logs, sms's, social media data, images posted to instagram and camera phone and CCTV footage. Advanced data pre processing was used to carry out automatic face recognition and other biometric identification. Although not designed specifically for counter terrorism but for criminal pattern analysis, systems such as NYPD's 'Domain Awareness' system are capable of similar feats and carry out integration of CCTV and traffic camera imagery along processing the imagery to extract number plates, speed and location being able to trace completely a vehicles journey throughout New York \citep{coscarelli2012nypd}. The system also can integrate data from arrays of IOT devices consisting of radiation and biochem sensors along with integration of traditional data sources.

\section{Terrorism research using data mining and statistical techniques}
Research into terrorism has also been enabled through machine learning and big data technologies. By integrating data from Google News with other information located in terrorist incident databases researchers were able to show a relationship and the type of attack and the group \citep{strang2015analyzing}.

Researchers have also been able to observe a power law between number of people killed and the frequency of terrorist incidents. To explain this phenomena researchers built a model to explain why this happens about how terrorist groups  dissolve and how often they can commit major atrocities and how easy it is for them to enlist  willing volunteers. The model almost perfectly reproduced the power distribution \citep{clauset2005scale}.

An investigation has also been carried out into why some groups persist over others. Using the global terrorist incident dataset controlling for well established theories regarding the longevity of terrorist group and theory around terrorism itself. A study explanation was constructed to account for the effect of inter terrorist group rivalry has on the length of time a terrorist group will persist. That is, the larger the number of terrorist group in a country the less likely the group will survive. The capacity and ability of a group to carry out transnational attacks, carry out different type of attacks, carry out attacks with higher levels of mortality the likelier it is to persist \citep{young2014survival}. Regression methods are quite common to the study of counter terrorism. Intervention analysis to quantify the effect of US interventions have on the number of attacks due to terrorism \citep{enders1993effectiveness}.

The application of social network analysis by researchers to terrorism has a long history dating back to the 1980's, when pioneering work by \citep{sterling1981terror} described links between different terrorist groups and their backers (the KGB), the IRA and Palestinian terrorist organisations. The application of network analysis has been shown to be one of the most fruitful means for carrying out terrorism research. A number of reasons have been cited for this, these include:
\begin{enumerate}
\item Social ties and social influence have been contended to be key in the course of someones radicalization \citep{hegghammer2006terrorist}. The reason for this being that most peoples company they keep and social connections where in place prior to some-ones radicalization.
\item Network methods allow for a true representation of the internal structure of terrorist organizations without introducing incorrect beliefs about how a terrorist group should behave. Instead it allows true structure of an organisations structure to emerge, often giving rise to the discovery of unexpeceted conclusions from the data such as the discovery of central actors, or channels of communications \citep{morselli2009inside}.
\item  The task of mapping terrorist networks is extremely useful from a counter terrorist perspective as it can potentially improve the capabilities of counter terrorist efforts. That is because through the pinpointing of key members whose removal would cause the most disarray to a terrorist network \citep{joffres2011strategies}. 
\end{enumerate}
The application of SNA to terrorism started in earnest after the September the 11th attacks in the US. Social graphs constructed after the event \citep{krebs2002mapping}, \citep{krebs2002uncloaking}  were used to visualize the connections between the hijackers and their support network who supplied financing, training and intelligence support to aid the in the attacks. The two central actors in the  network Nawaf Alhazmi and Khalid Almihdha were never more than two links from any of the other nodes (in this case the terrorists and their support in the network). it was stated by \citep{krebs2002mapping} that if closer attention had been paid to disrupting the activities of key actors in the network, individuals with high connectivity and a distinctive skill set, the network once it has been found can be more easily disrupted. \citep{sageman2004understanding} utilised the profile and history of 366 members of the "global Salafi network" to construct a network based upon a number of characteristics including extended and immediate family ties, acquaintanceship, religious beliefs and work associations and affiliations. Four large clusters were identified around Al Qaeda central staff, north African Arabs (Arab Shamal Ifriqiya), middle eastern Arabs and south east Asia (Indonesia and Malaysia). Analysis of terrorist cells found a large density of ties between 17 members of large Jemaah Islamiyah cell that carried out the Bali bombings in 2002 \citep{koschade2006social}. Both the operational leader and organizational and support structure leader had largest score on a number of different centrality measures, which indicated they were key actors in the network. Due to the high connectivity of the cell and the high centrality of key figures in the network, discovery of one member would have led to the detection of the whole network. Network theory has also shown the changing structure of terrorists from a top down corporate like structure, to a coupled network structure to a loosely coupled network \citep{jackson2006groups}. SNA has been also used in conjunction with other tools such information extraction using text mining to automate the elucidation of data germane to the discovery of network structure of a terrorist network. Such an approach has been used to create a terrorist behavioural activity model \citep{ball2016automating}.

Unsupervised methods such as HMM's and clustering have also seen use within terrorism research. HMM's have been used to model the temporal evolution of suspicious behavioural patterns in terms of financial records, intelligence communique's, media (print and web) articles and email communications. HMM's have been used with this data to identify atypical behaviour of terrorist activities from the signal associated with normal behaviour\citep{allanach2004detecting}.HMM's have also been applied to the study of the activity patterns of terrorist groups, that is spurt in activity or sudden drops in activities or an end to the groups activity. To do this a n-state hidden markov model is developed which captures the inherent states underpinning the the dynamics of a terrorist organization and from this an activity profile for the group can be developed.

An alternative to the use of HMM's have also been applied to the study of recording differences in its organisational health and ability to rebound as well as its level of organisation is to use a method based on the detection of large increase in the activity profiles of groups. This approach involves binning the count data associated with terrorist activity and then analyzing  them in comparison to one another. These observation vectors of terrorist data are then transformed via a series of functionals inspired by the use of majoritization theory schema to deliver a spurt classification. This methodology was found to give a small number of incorrect classifications when compared to the parametric methods such as HMM \citep{raghavan2016tracking}. 
Clustering has been applied to spatial analysis of crime patterns. Clustering has been used to construct crime motifs \citep{nath2006crime}. Applied spatial analysis has also been applied for spatial forecasting terrorist events. Through the use of non-smooth demographic prediction to enhance the spatial prediction, substantial  increase in forecasting power is achieved over the base model (utilizing past locations to predict future locations of attack) \citep{brown2004spatial}.

\section{The history of terrorism datamining, a German, US and Israeli perspective}
Data mining has been applied to not only study of terrorism but also to investigative analysis of terrorism. One of the first known instances of this was in West Germany in the 1970's when the German state in the face of dedicated attack by far left terrorist  groups such as the RAF (Red Army Faction) and the red brigades aided and supported by Warsaw Pact countries \citep{leighton2014strange} and the acquiescence of these groups to aid in terrorist attacks by other groups such as Black September
\citep{nacos2016terrorism}. The West German states adoption of the ideal of militant democracy (streitbare Demokratie), the giving of a comprehensive set of powers to defend a liberal democracy against those who wish to get rid of it and establish a totalitarian state \citep{rosenfeld2014militant}. To lesson the overreaching effects of such sweeping powers the West German state was one of the first to adopt data mining techniques to group or cluster suspected members of terrorist groups so as to aid in targeting the correct group of individuals, through development of dragnet (Rasterfahndung), the integration of data from a number of different data sources to essentially act as  a filter, so as to narrow the number of individuals to investigate \citep{weinhauer2014terror}. This technique had a number of benefits not only to aiding in the investigation but also massive societal benefits, these were:
\begin{enumerate}
\item An efficient, targeted search for RAF operatives, which resulted in the defeat, elimination, arrest of the leadership \citep{hauser1997baader} and destruction of the first generation of the RAF \citep{weinhauer2006terrorismus}, though the actions of the RAF did continue up until the early 1990's.
\item It was a targeted intelligence led investigation, not targeting innocent members of the public, which had been evident in previous uses of the concept of militant democracy, \citep{de2010counter}.
\end{enumerate}

Israel due to its unique geo-political position has led to it developing advanced counter terrorism datamining capabilities. Israel faces a terrorist foe who now not only use the web to propagandise terrorism, fundraise,  but also use it as a strategic tool to direct terrorism. Terrorists have also used widely available geodesic data  as an intelligence tool to plan to carry out attacks. Handheld GPS or devices (such as smart phones) with GPS sensors can be used to then coordinate attacks. One of the most high profile cases of cyber terrorism against Israel was the breach of an IDF  spokesmans Twitter which was used to spread  malicious misinformation regarding a leak at the nuclear facilities at Dimona \citep{Israeltwitterhack}.
As part of Israel's overall counter intelligence strategy is terrorist informatics, with the five elements of its strategy being \citep{tucker2003strategies}:
\begin{enumerate}
	\item Data collation, analysis and investigation.
	\item Military, intelligence and paramilitary operations to target terrorist groups.
	\item Biometrics and security measure to protect passengers on mass transit systems particularly the airline industry.
	\item Prevention of chemical, biological and nuclear attacks. This includes the use of arrays of sensors, the integration of this information and the analysis of this information.
	\item Improving the moral of the people and strengthen the resolve of the population in coping with a sustained campaign of terrorism operated against it. Israel has affected a policy of marginal gains to affect this particular strategy. This is the aggregation of small changes delivered by the methods above but also structural or environmental changes that led to significant changes in the security of the nation. This system of marginal gains has been recently popularized by David Brailsford who popularized the technique with the general public \citep{durrand2014pre} and who used it to massively improved the performance of the British cycling team. Similarly Israel has seen the use of everything from data mining to structural changes to its city to its pioneering use of airport scanners and pre flight screening has seen it dramatically reduce the number of fatalities from terrorism. For instance when in 2014 a Palestinian terrorist attempted to crash his cars into a number of pedestrians queueing at a bus stop , he was prevented from doing so by a concrete bollard \citep{Israelcounterterrorismlesson}. 
\end{enumerate}
As a response Israel has developed sophisticated information technology based tools to support counter terrorism. These tools are focussed on securing Israel's communication networks from cyber attack and the gathering of information  from disparate sources such intelligence reports and national and international anti terrorist databases to give a detailed collected, concise and complete assessment of threats and highlights the most high risk of these. This system is currently operated by numerous countries through out the world. This system came to large scale public attention in 2015 due to leaks within the French security services about its non adoption \citep{Israelcounterterrorismlessonfrance}. 
The security services blamed its non adoption on political pressures. The non-adoption of the system and lack of similar capabilities was directly attributed by the same person as one of the failures in counter intelligence that led to the dereliction to detect the Paris attacks. The Israeli company Verint specializes in software designed to integrate and collate data from disparate sources  providing analysis to security specialists \citep{zureik2010surveillance}.

Israel's response to terrorism has also prompted a large interest in IOT, especially  computerized perimeter security systems. These systems use  large arrays of sensors CCTV camera, trip wire detection, IR (infra-red) detection, collect the information process it and automatically analyze to detect intrusions. Companies such as IDSST and Orad Group \citep{gordon2011israel} have commercialized such systems and implemented solutions throughout the world for everything from  protecting industrial plants, key infrastructure to helping securing the US Mexico border.

Since the September the 11th attacks of 2001 to 2011 it is estimated that the US spent 1 trillion dollars on approaches and polices to fight against terrorism \citep{roche2015intelligence}. The rise of big data technologies has been correlated with the US's increase in use of data mining technology in counter terrorism. As previously stated the US had been deploying data mining for counter terrorist  purposes pre 9-11, in the form of Able danger which was purported to have identified some of those involved  in the attacks. Other systems which predated 9-11 were link detection tools such as EELD \citep{mooney2002relational} which was an information  elicitation and link investigation tool which later became part of NSA's TIA program \citep{deibel2016nsa}. TIA was a program that was established by DARPA, which was focussed on the application of both surveillance and gathering of information to the automated  or semi automated analysis and identification of terrorists and other asymmetric actors who may pose a threat to the US. The US has embraced data mining technologies and while mass surveillance systems were officially defunded by congress in 2003 a number of these projects were later reclassified under different names and were continued to be run. These programs gave rise to such systems as PRISM (SIGAD US-984XN). 
PRISM is a mass surveillance system which collects  a large amount of information relating to internet traffic including searching emails, search history, file hosting service providers, instant messaging, video chat and voice calls over the web etc. Any information that then matches court approved search terms (under the FISA amendments act of 2008) are handed over to the NSA and are collected and analysed by PRISM. While PRISM remains somewhat controversial its importance to counter terrorism is reported to be significant and in the words of NSA Director (in 2013) General Keith Alexander before congress  as "uniquely valuable intelligence". However others have criticized the system and it's usefulness stating that claims where the system played a pivotal role the information uncovered could have been found trough other means. This was most apparent in the case of Najibullah Zazi where the NSA claimed the use of PRISM and its unique capabilities had been key in investigating and the capture of the budding New York city bomber. These claims were quickly refuted and  a number of systems that could have provided the same information could  have been provided by other information \citep{NSAAtlanticWire2013}.However this was quickly repudiated  and it was shown that a number of systems could have provided the information. Other less known systems developed for US customs and Border Protection forces who created ATS and secure flight used by the TSA. Secure flight is a flight screening system currently in service with the TSA \citep{spear2015secure}. While Automatic Targeting system is a screening system employed by US custom and Border protection \citep{jizba2015analysis}. ATS was attributed with recognising Rael al-Banna as a potential terrorist and barred his passage to the US in 2003.

This has also had the effect much in a similar way to Israel the commercialization of sophisticated platforms such as Palantir which consolidates different types of data from different systems \citep{soklakova2016technological}, then creates a number of graph models based on the different sources of data and also provides additional advanced analysis capabilities.

\section{Problems associated with data mining and counter terrorism?}

We have seen so far for data mining for counter terrorism purposes it has a number of use cases exist, these are:
\begin{enumerate}
\item Risk assessment. This can be either classification of a person as a terrorist   or scoring risk for a person.
\item Generation of profiles. This involves the collection and collation of information on person providing this in a  easy to digest format, providing simple self discovery tools to the user.
\item Discovery of networks. Link analysis, graph theory and graph visualization to allow discover of terrorist networks.
\item Data collection and collation. This is the process of collection of data and data about that data (meta data) from disparate sources, cleaning the data, treatment of missing values and the storage of this data in readily available repository for querying by analysts.
\end{enumerate}

Each of these poses problems from a technical, moral and legal perspective. These problems are discussed below but can be restricted to the following areas:
\begin{enumerate}
\item The dangers of misuse of mass surveillance, to target, minorities, people of differing politics.
\item The problem of class imbalance when building a predictive model of having relatively few samples to train on.
\item The related problem of the 'base rate fallacy' \citep{bar1980base}. This is common in a number of areas where the base rate of occurrences of what a statistical test or a machine learning algorithm is quite low, including fraud detection and intrusion detection \citep{axelsson2000base}.
\item The use of unsupervised methods where there is a very low frequency of a signal for terrorist behaviour.
\end{enumerate}

\subsection{The dangers of mass surveillance and its misuse}
While datamining can be an important counter terrorism tool its use especially when used in tandem with mass surveillance techniques. There are many examples of these systems being misused in both democratic regimes and non democratic regimes. The misuse of mass surveillance techniques pre-date the digital computer. Examples of this would  be the attempted mass conscription of Norwegian males. On learning of the proposed plan Norwegian resistance fighters instead of destroying the files which were going to be used to base the conscription orders of the men, they destroyed the machines used to sort the data. Without the necessary information to aggregate the population data, A draft of the Norwegian populace was too difficult to instantiate without access to properly aggregated by age cohort data \citep{bignami2007european}. Abuses of these techniques are not just limited to totalitarian regimes but also to democratic ones. During the civil rights era in the US, the FBI frequently wire-tapped Dr. Martin Luther King with his colleagues in the civil rights movement \citep{garrow2015fbi}. The wiretaps were done to try and establish whether Dr. King had any ties with the Soviet Union. Other notable examples of this are the Lyndon Johnston administrations use of mass surveillance to investigate if the Barry Goldwaters staff were homosexual's in the 1964 presidential elections \citep{sales2014domesticating}.

\subsection{The problem of class imbalance in counter terrorism datamining} 
One of the criticisms of data mining is that very few training patterns exist in terrorism due to the relatively few cases of it. This low frequency of it occurring has made it very difficult to detect. When carrying out a classification to build a model , this problem is referred to as class imbalance \citep{SASClassimbalance2015}. If this problem is not extremely severe certain actions which involve either sampling (over or under sampling of minority/majority class), algorithmic means (using algorithms that are less susceptible to class imbalance), using cost based classification techniques or using synthesized artificial minority classes as surrogates for the minority class. However if the class imbalance is very severe the above methods will not be effective especially over/under sampling, which will only serve to train a model to identify specific examples \citep{jonas2006effective}.

\subsection{The problem of low base rates of terrorism in counter terrorism datamining}
This problem is exasperated by the fact even if you can train a model to accurately predict terrorist behaviour, the base rate of terrorism is so low the model may not be useful \citep{jensen2003information}. The base rate fallacy can be best explained with the following example. if the frequency of terrorists is actually low which it is lest assume it to be 100 in 1,000,000 terrorists. Say if we build a system which has a true positive rate of 99\% (sensitivity, also referred to as the recall, this measures the proportion of positives are are rightly classified) and a true negative rate of 99\% (specificity, the proportions of negatives that are classified rightly) then in a city of 1,000,000 inhabitants where there are 100 terrorists. 99 out of 100 terrorists will will be classified correctly. of the 999,900 of the non terrorists 9999 will be wrongly identified as terrorists. Therefore the detection rate will be about 99/(9999+99), which is  0.009803922 correctly,this at best could function as a filter. 

Bayes theorem states that:

\begin{equation} p(A|B)=P(B|A)P(A)/P(B) \label{eq1bayes}  \end{equation}

Where A and B are observed incidents, P(A) and P(A) are the probabilities of said events, and P(A$\vert$B) is a conditional probability of observing incident A given that B is true. P(B$\vert$A) is the conditional probability of observing incident B given that A is true. from this we can get the equation for terrorist events occurring  \label{eq2bayes}.
 
\begin{equation} p(terrorist|T)=p(T|terrorist)p(terrorist)/p(T) \label{eq2bayes}  \end{equation}

Where T means the algorithm indicates the person as a terrorist.

The base rate fallacy is not uncommon and exists in other fields, in other related criminal investigation fields such as fraud detection. Other problems arise to with data mining approaches to counter terrorism, bad data quality due to a myriad of reasons, missing data, misinterpreted field or inconsistent report. 

\subsection{Low observable signal for terrorism and the use of unsupervised methods}
To overcome this difficulty data mining for terrorism has instead tried to detect anomalous information, but again anomalous behaviour may not be indicative of terrorist behaviour just behaviour which is outside the norm \citep{thuraisingham2004data}. Therefore if incorrectly used data mining can exacerbate a problem of trying to identify terrorists, however if used to support investigators in collating information acting as a filter to narrow down a list of suspects data mining can be effective.

\section{Overview of the use of data mining for terrorism}
Data mining has evolved as a powerful supplemental to traditional intelligence methods such as sigint and humint and newer intelligence methods such as an enabler for more advanced methods such as cyber-terrorism. Data mining has been used to study both its application to counter terrorism as its application tot he study of terrorism itself. A number of different data mining  types (supervised and unsupervised) methods  have been applied to both the study of terrorism and counter terrorism. A related field to data mining for the study of terrorism is the field of terrorism informatics, which also encompasses the collation, collection and cleaning of data along with the presentation of the data in a simple to interact with manner. Terrorism informatics systems may be also required to ingest data from many disparate sources, for instance IOT banks of sensors or social media data.

Problems arise to with data mining approaches to counter terrorism, bad data quality due to a myriad of reasons, missing data, misinterpreted field or inconsistent report.
If incorrectly used data mining can cause problems:
\begin{itemize}
\item Rare occurrences and low base rates of terrorism make application of structured data mining techniques impossible to use for counter terrorism purposes.
\item Rare occurrence of acts and characteristics of each terrorist act which  makes the act unique,makes the application of  data mining techniques difficult whether unstructured or structured can be a waste of time as the signal for terrorism is very low.
\end{itemize}

US experience with PRISM and other TIA related projects have so far proven that mass
surveillance does not work and instead can over burden an analyst with the amount of false positives it generates. Big data technologies are not a panacea for the underlying problems  of low base rates of terrorism and the massive class imbalance in terrorists/non-terrorists \citep{Masssurvelilancefail2015}. However if used as a a support to an analyst in a directed investigation and employed in a wider top down approach to counter terrorism (as the Israeli experience) data mining and auto collection of data remain an effective counter terrorist tool. US experience with mass surveillance technologies like
PRISM has though us that  due to the underlying mathematics (Bayes rule and the base rate fallacy) \citep{schneier2015data}. 

However data mining is an effective means to carry out research into terrorism especially after an incident has occurred. Of particular interest is graph theory and the use of unsupervised methods (Hidden Markov Models) to try to understand the behaviour of groups. Data mining has also been successful in the application of supervised techniques particularly variance autoregressive regression and time series analysis (modelling the effectiveness of interventions) along with survival analysis in the analysis of what factors effect the longevity of a terrorist group.  

 

