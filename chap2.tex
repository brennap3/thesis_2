\chapter[Datamining and statistical approaches to research in terrorism and counter terrorism]{Datamining approaches to research in terrorism}
\chaptermark{datamining terrorism research}

To counter terrorism not only requires that governments research new methods to collect and assemble intelligence but also to scrutinize it so as produce actionable insights. During the cold war much intelligence could be gained by utilizing a limited number of sources which were rich in information and analysis of such, could gleam a large amount of understanding into an enemies effectiveness and competencies in different areas, their disposition and stratagem. Traditional methodologies used in intelligence gathering include \citep{tanner2014examining}:
\begin{enumerate}
\item HUMINT (human intelligence) is intelligence collected from actors on the ground. These can include specialist troops, intelligence operatives, captured combatants.
\item GEOINT (Geospatial intelligence) Geo-spatial analysis carried out by satellites, drones and dedicated spy planes.
\item MASINT (Measurement and signature intelligence). This is a methodology  used in intelligence gathering to identify, trace and recognize characteristics of source targets. Sources of MASINT would include radar and acoustic intelligence. The most famous of these would be SURTASS and SOSUS \citep{noles2003judge} which are collections of hydrophones used to track surface and sub-surface maritime traffic.
\item SIGINT (Signal intelligence), this is the analysis of intercepted signals by ground stations or dedicated SIGINT aircraft \citep{aid2003all}.
\item TECHINT (Technical intelligence), is intelligence gathered from the technical analysis of equipment.
\item FININT  (Financial intelligence) is the generation of intelligence from analysis of financial records.
\item CYBINT/OSINT (Cyber intelligence and Open Source intelligence) \citep{csahinnew} is information gathered from the web or open source intelligence and would be considered a new form of intelligence. Automated data mining and data analysis (including data integration) can be applied to both old and new intelligence methodologies but has been applied most notably to CYBINT and OSINT and has in-fact largely enabled these fields.

However for all methodologies (not just CYBINT and OSINT) data integration is important, enabling the analysis of disparate types of data such as text, audio, biometric information, technical plans and imagery gathered from different sources and gathered using different intelligence techniques.
\end{enumerate}

\section{Terrorism informatics}

Terrorism informatics is the utilization of a number of different techniques for combining disparate data from different sources and analysis of the data to provide insights to intelligence specialists \citep{chau2015intelligence}. This requires a number of methodologies and system sourced from a number of different disciplines which include computer science, business informatics, statistics, machine learning, computational linguistics and social network analysis. The analysis needed to produce actionable insights is usually produced in two ways by either data analysis and/or data mining. A framework for data mining for counter terrorism  includes problem description, data gestation, data mining, model appraisal and illustrating or reporting the knowledge gained in a succinct form.

Data mining is the automated extraction of hidden patterns from databases \citep{shmueli2016data}. Established data mining approaches include supervised methods such as  classification, regression/prediction or forecasting. Unsupervised methods include such methodologies as association rules mining, cluster analysis and outlier detection. More recent developments for identification of patterns within data include entity extraction. This is used to analyse text imagery, audio recordings and has been utilized to automatically identify suspects, whereabouts, cars and personnel traits from police reports. Data mining began to seriously grab the attention of the US government in 2002 (as a response to the September 11th of 2001 attacks) as a means to counter terrorism. Data mining efforts applied to the investigation of terrorism had pre-empted September 11 by a number of years with the building of 'Able Danger', a counter terrorist data mining tool. 'Able Danger' \citep{keefe2006can} had identified a number of the 9/11 terrorists prior to the attacks but the intelligence services had failed to act on it \citep{lance2006triple}. This has been superseded by other data mining tools (particularly network access tools) such as the NSA's special access program which builds a social web from a suspect person, examining their links to people, through emails, phones, address and other information used to link people. This type of network based on links is one means to carry out social network analysis, another means of using network analysis to detect suspect behaviour is to use affiliation networks. These are networks in which members of the network are connected by having common interests and has been shown to be effective in corporations detecting fraud \citep{ben2009organised}.

Automated data analysis involves the automation of data analysis through the use of subject based queries or pattern based queries. Subject based queries start with a specific subject and expand out from this subject by finding entities linked to this person. These could be other people, places, vehicles, phone numbers, emails or activities. This type of analysis is often referred to as link analysis \citep{berry1997data} and has not only been used for terrorism research but has found commercial usage within fraud investigation work in the financial sector particularly in banking and insurance. The benefit of using this approach is that it can be used to find leads to other person(s), places, vehicles, phone numbers or emails. Commercial based systems such as I2 \citep{i2Analyze2016} (which is also used by military, intelligence and law enforcement) is used within fraud prevention units to investigate fraudulent claims and financial transactions.

Pattern based query automated data analysis involves the use of a pattern or a predictive model to identify a particular type of behaviour in a dataset. Again this type of analysis has seen considerable commercial (and by the military and law enforcement) adoption, for example Detica NetReveal \citep{oatley2011data} which is used for finding patterns of credit card fraud amongst other applications in the financial services.  

Before analysis of the data takes place, the data must first be collated, the quality assessed and then if necessary be cleansed. At it's simplest, this process may involve removal of identical records, normalizing the data, removing unneeded data (not only because it may be unneeded but because it may be illegal to hold such data due to privacy laws). Other typical tasks would be the consideration of missing data and how to allow for it (for example through imputation of missing values) and the regulation of data types. More advanced pre-processing would include integration of disparate data through extraction of metadata from the original data \citep{derosa2004data}. Examples of this would include extraction of  time and place from a temporal and geo-tagged photograph. Also the heterogeneous nature of data used in counter terrorism have necessitated the adoption of new types of database technology which allow for the storage and querying of heterogeneous data.  

Data stored in a NOSQL database does not require data to be cleansed to the extent it must be to be useful, when stored in a non NOSQL (typically relational database) database. NOSQL also allows the storage of more data (and different types of data) and is extremely important were a lot of data is generated such as analysis of logs, sensor data (or large arrays of sensors in the case of IOT) or social media \citep{jeberson2015survey}.

\section{Data mining approaches for counter terrorism}

Due to the transnational nature of  modern terrorism, the emergence of the internet to enable rapid communication and the decentralized nature of these groups, automatic collection and analysis of data allows examining text for words or phrases synonymous with terrorism.  The DHS (Department of Homeland Security) uses a system to carry out entity extraction for terrorist specific terms such as 'Sarin', 'Anthrax' \citep{merrick2015outthinking}, and different types of improvised explosive devices. These systems if they work coupled with information from financial details, social network information and geodesic data can give an investigator a much richer set of data to investigate and also give more context to alerts raised on people or places regarding potential attacks. 

Though complex investigations involving large complex multiple data source and data type investigations remains a huge challenge for the intelligence services. In the 2013 Boston bombings 10 tb of data were generated within 24 hours of the crime by the FBI regarding the terrorist incident \citep{jeberson2015survey}. The data came from a number of disparate sources including phone tower cell call logs, sms's, social media data, images posted to instagram and camera phone and CCTV footage. Advanced data pre-processing was used to carry out automatic face recognition and other biometric identification. Although not designed specifically for counter terrorism but for criminal pattern analysis, systems such as NYPD's 'Domain Awareness' system are capable of similar feats and carry out integration of CCTV and traffic camera imagery along with processing the imagery to extract number plates, speed and location data, being able to trace completely a vehicles journey throughout New York \citep{coscarelli2012nypd}. The capabilities of the system can be further enhanced through the integration of data from arrays of IOT devices consisting of radiation and biochem sensors along with integration of more traditional data sources.

\section{Terrorism research using data mining and statistical techniques}
Research into terrorism has also been enabled through machine learning and big data technologies. By integrating data from Google News with other information located in terrorist incident databases researchers were able to show a relationship between particular types of attack and individual groups ideology \citep{strang2015analyzing}.

Researchers have also been able to observe a power law relationship between number of people killed and the frequency of terrorist incidents. To explain this phenomena, researchers built a model to explain why this happens, about how terrorist groups dissolve and how often they can commit major atrocities and how easy it is for them to enlist willing volunteers. The model almost perfectly reproduced the power distribution \citep{clauset2005scale}.

An investigation has also been carried out into why some groups persist over others. Using a dataset partially sourced from the global terrorist incident database (GTD) controlling for well established theories regarding the longevity of terrorist group and theory around terrorism itself. An explanation was constructed from the study to account for the effect of inter terrorist group rivalry has on the length of time a terrorist group will persist. That is, the larger the number of terrorist groups in a country the less likely the group will survive. The capacity and ability of a group to carry out transnational attacks, carry out different type of attacks, carry out attacks with higher levels of mortality the likelier it is to persist \citep{young2014survival}. Regression methods (particularly survival) are quite common to the study of counter terrorism. Particularly, intervention analysis to quantify the effect of US interventions (to combat terrorism) have had on the number of attacks due to terrorism \citep{enders1993effectiveness}.

The application of social network analysis by researchers to terrorism has a long history dating back to the 1980's, when pioneering work by \citep{sterling1981terror} described links between different terrorist groups and their backers (the KGB), the IRA and Palestinian terrorist organisations. The application of network analysis has been shown to be one of the most fruitful means for carrying out terrorism research. A number of reasons have been cited for this, these include:
\begin{enumerate}
\item Social ties and social influence have been contended to be key in the course of someone's radicalization \citep{hegghammer2006terrorist}. The reason for this being that most peoples company they keep and social connections where in place prior to some-ones radicalization.
\item Network methods allow for a true representation of the internal structure of terrorist organizations without introducing incorrect beliefs about how a terrorist group should behave. Instead it allows the true composition and form of an organisations structure to emerge, often giving rise to the discovery of unexpected conclusions from the data such as the discovery of central actors, or channels of communications \citep{morselli2009inside}.
\item  The task of mapping terrorist networks is extremely useful from a counter terrorist perspective as it can potentially improve the capabilities of counter terrorist efforts. That is because it allows the pinpointing of key members whose removal would cause the most disarray to a terrorist network \citep{joffres2011strategies}. 
\end{enumerate}
The application of SNA to terrorism started in earnest after the September the 11th attacks in the US. Social graphs constructed after the event \citep{krebs2002mapping}, \citep{krebs2002uncloaking}  were used to visualize the connections between the hijackers and their support network who supplied financing, training and intelligence support to aid the in the attacks. The two central actors in the network Nawaf Alhazmi and Khalid Almihdha were never more than two links from any of the other nodes (in this case the terrorists and their support in the network). It was stated by \citep{krebs2002mapping} that if closer attention had been paid to disrupting the activities of key actors in the network, individuals with high connectivity and a distinctive skill set, the network once it had been found it could have been easily disrupted. \citep{sageman2004understanding} utilised the profile and history of 366 members of the "global Salafi network" to construct a network based upon a number of characteristics including extended and immediate family ties, acquaintanceship, religious beliefs and work associations and affiliations. Four large clusters were identified around Al Qa'ida central staff, north African Arabs (Arab Shamal Ifriqiya), middle eastern Arabs and south east Asia (Indonesia and Malaysia). Analysis of terrorist cells found a large density of ties between 17 members of a large Jemaah Islamiyah cell that carried out the Bali bombings in 2002 \citep{koschade2006social}. Both the operational leader and organizational and support structure leader had the largest score on a number of different centrality measures, which indicated they were key actors in the network. Due to the high connectivity of the cell and the high centrality of key figures in the network, discovery of one member would have led to the detection of the whole network. Network theory has also shown the changing or evolving structure of terrorists from a top down corporate like structure, to a coupled network structure to a loosely coupled network \citep{jackson2006groups}. SNA has been also used in conjunction with other tools such as information extraction using text mining to automate the elucidation of data germane to the discovery of the network structure of a terrorist network. Such an approach has been used to create terrorist behavioural activity models \citep{ball2016automating}.

Unsupervised methods such as HMM's and clustering have also seen use within terrorism research. HMM's have been used to model the temporal evolution of suspicious behavioural patterns in terms of financial records, intelligence communique's, media (print and web) articles and email communications. HMM's have been used with this data to identify atypical behaviour of terrorist activities from the signal associated with normal behaviour\citep{allanach2004detecting}. HMM's have been applied to the study of the activity patterns of terrorist groups, that is spurt in activity or sudden drops in activities or an end to the groups activity. To do this a n-state hidden markov model (HMM) is developed which captures the inherent states underpinning the the dynamics of a terrorist organization and from this an activity profile for the group can be developed.

An alternative to the use of HMM's for the study of terrorist groups organisational health and ability to rebound as well as its level of organisation is to use a method based on the detection of large increase in the activity profiles of groups. This approach involves binning the count data associated with terrorist activity and then analysing them in comparison to one another. These observation vectors of terrorist data are then transformed via a series of functionals inspired by the use of majoritization theory schema to deliver a spurt classification. This methodology was found to give a small number of incorrect classifications when compared to the parametric methods such as HMM \citep{raghavan2016tracking}. 

Clustering has been widely applied to spatial analysis of crime patterns. Particularly clustering has been used to construct crime motifs \citep{nath2006crime}. Applied spatial analysis has also been applied for the purpose of spatial forecasting terrorist events. Through the use of non-smooth demographic prediction to enhance the spatial prediction of terrorist events, substantial  increase in forecasting power is achieved over the base model (utilizing past locations to predict future locations of attack) \citep{brown2004spatial}.

\section{The history of terrorism informatics, a German, US and Israeli perspective}

Terrorism informatics (and in particular data mining and data analysis) has been applied to not only the study of terrorism but also to investigative analysis of terrorism. One of the first known instances of this was in West Germany in the 1970's. The German state was faced with a dedicated campaign of attacks by far left terrorist groups such as the RAF (Red Army Faction) and the red brigades aided and supported by Warsaw Pact countries \citep{leighton2014strange} and the acquiescence and support of these groups to aid in terrorist attacks by other groups such as Black September
\citep{nacos2016terrorism}. The West German states response was the adoption of the ideal of militant democracy (streitbare Demokratie), the giving of a comprehensive set of powers to defend a liberal democracy against those who wish to get rid of it and establish a totalitarian state \citep{rosenfeld2014militant}. To lesson the overreaching effects of such sweeping powers the West German state was one of the first to adopt data mining techniques to group or cluster suspected members of terrorist groups so as to aid in targeting the correct group of individuals, through development of dragnet (Rasterfahndung). Dragnet was the integration of data from a number of different data sources to essentially act as  a filter, so as to narrow the number of individuals to investigate \citep{weinhauer2014terror}. This technique had a number of benefits not only to aiding in the investigation but also massive societal benefits, these were:
\begin{enumerate}
\item An efficient, targeted search for RAF operatives, which resulted in the defeat, elimination, arrest of the leadership \citep{hauser1997baader} and destruction of the first generation of the RAF \citep{weinhauer2006terrorismus}. Though it did disrupt the RAF it did not cause their elimination and the actions of the RAF did continue up until the early 1990's.
\item It was a targeted intelligence led investigation, not targeting innocent members of the public, which had been evident in previous uses of the concept of militant democracy, \citep{de2010counter}.
\end{enumerate}

Israel due to its unique geo-political position has led to it developing advanced counter terrorism data mining capabilities. Israel faces a terrorist foe who now not only use the web to propagandise terrorism, fundraise, but also use it as a strategic tool to direct terrorism. Terrorists have also used widely available geodesic data as an intelligence tool to plan to carry out attacks. Handheld GPS or devices (such as smart phones) with GPS sensors can be used to coordinate attacks. Israel has also been victim to some of the more advanced or new tactics of the terrorist including cyber terrorism, one of the most high profile cases of cyber terrorism against Israel was the breach of an IDF  spokesman's Twitter which was used to spread  malicious misinformation regarding a leak at the nuclear facilities at Dimona \citep{Israeltwitterhack}.
As part of Israel's overall counter intelligence strategy is counter terrorist informatics, with the five elements of its strategy being \citep{tucker2003strategies}:
\begin{enumerate}
	\item Data collation, analysis and investigation.
	\item Military, intelligence and paramilitary operations to target terrorist groups.
	\item Biometrics and security measure to protect passengers on mass transit systems particularly the airline industry.
	\item Prevention of chemical, biological and nuclear attacks. This includes the use of arrays of sensors, the integration of this information and the analysis of this information.
	\item Improving the moral of the people and strengthening the resolve of the population in coping with a sustained campaign of terrorism operated against it. Israel has affected a policy of marginal gains to affect this particular strategy. This is the aggregation of small changes delivered by the methods above but also structural or environmental changes that led to significant changes in the security of the nation. This system of marginal gains has been recently popularized by David Brailsford who promoted the technique with the general public \citep{durrand2014pre} and who used it to massively improve the performance of the British cycling team. Similarly Israel has seen the use of everything from data mining to structural changes to its city to its pioneering use of airport scanners and pre flight screening to dramatically reduce the number of fatalities from terrorism. For instance when in 2014 a Palestinian terrorist attempted to crash his car into a number of pedestrians queueing at a bus stop, he was prevented from doing so by a concrete bollard \citep{Israelcounterterrorismlesson}  used to cordon off pedestrian areas from motor vehicles and potential motor based terrorist attacks. Such devices may have prevented the nice attacks of 2016. These attacks employed a 16 tonne cargo truck driven into large crowds of people gathered on a promenade\citep{nesser2016jihadi}. 
\end{enumerate}

As a response to terrorism, Israel has developed sophisticated information technology based tools to support counter terrorism. These tools are focussed on securing Israel's communication networks from cyber attack and the gathering of information from disparate sources such as intelligence reports and national and international anti terrorist databases to give a detailed collected, concise and complete assessment of threats and highlights the most high risk of these. This system is currently operated by numerous countries through out the world. This system came to large scale public attention in 2015 due to leaks within the French security services about its non adoption \citep{Israelcounterterrorismlessonfrance}. 
The security services blamed its non adoption on political pressures. The non-adoption of the system and lack of similar capabilities was directly attributed by the same person as one of the failures in counter intelligence that led to the dereliction to detect the Paris attacks. Such systems are currently offered by Verint. The Israeli company Verint specializes in software designed to integrate and collate data from disparate sources providing analysis to security specialists \citep{zureik2010surveillance}.

Israel's response to terrorism has also prompted a large interest in IOT, especially  computerized perimeter security systems. These systems use large arrays of sensors, CCTV cameras, trip wire detection, IR (infra-red) detection which is then collected. The information is then processed and automatically analysed so as to detect intrusions. Companies such as IDSST and Orad Group \citep{gordon2011israel} have commercialized such systems and implemented solutions throughout the world for everything from  protecting industrial plants, key infrastructure to helping securing the US Mexico border.

Since the September the 11th attacks of 2001 to 2011 it is estimated that the US has spent 1 trillion dollars on approaches and polices to fight against terrorism \citep{roche2015intelligence}. The rise of big data technologies has been correlated with the US's increase in use of data mining technology in counter terrorism. As previously stated the US had been deploying data mining for counter terrorist purposes pre 9-11, in the form of Able danger which was purported to have identified some of those involved in the attacks. Other systems which predated 9-11 were link detection tools such as EELD \citep{mooney2002relational} which was an information elicitation and link investigation tool which later became part of NSA's TIA (Total Information Awareness) program \citep{deibel2016nsa}. TIA was a program that was established by DARPA, which was focussed on the application of both surveillance and gathering of information to the automated or semi automated analysis and identification of terrorists and other asymmetric actors who may pose a threat to the US. The US has embraced data mining technologies and while mass surveillance systems were officially defunded by congress in 2003 a number of these projects were later reclassified under different names and were continued to be run. These programs gave rise to such systems as PRISM (SIGAD US-984XN). 

PRISM is a mass surveillance system which collects a large amount of information relating to internet traffic including searching emails, search history, file hosting service providers, instant messaging, video chat and voice calls over the web etc. Any information that then matches court approved search terms (under the FISA amendments act of 2008) are handed over to the NSA and are collected and analysed by PRISM. While PRISM remains somewhat controversial it's importance to counter terrorism is reported to be significant and in the words of NSA Director (in 2013) General Keith Alexander before congress as being responsible for generating "uniquely valuable intelligence". 

However others have criticized the system and it's usefulness stating that claims where the system played a pivotal role the information uncovered could have been found through other means. 

This was most apparent in the case of Najibullah Zazi where the NSA claimed the use of PRISM and its unique capabilities had been key in investigating and the capture of the budding New York city bomber. These claims were quickly refuted and a number of systems that could have provided the same information were identified \citep{NSAAtlanticWire2013}. Other less known systems are those developed for US customs and Border Protection forces who created ATS (Automatic Targeting System) and secure flight used by the TSA (Transportation Security Administration). Secure flight is a flight screening system currently in service with the TSA \citep{spear2015secure}. While ATS is a screening system employed by US custom and Border protection \citep{jizba2015analysis}. ATS was attributed with recognising Rael Al-Banna as a potential terrorist and barred his passage to the US in 2003.

The investment in these technologies has also been followed by the commercialization of these technologies for non security purposes. This has also had the effect much in a similar way to Israel in the creation of successful commercial entities based on the technologies pioneered by the security systems.  An example of this would be the commercialization of sophisticated platforms such as Palantir which consolidates different types of data from different systems \citep{soklakova2016technological}, then creates a number of graph models based on the different sources of data and also provides additional advanced analysis capabilities.

\section{Problems associated with data mining and counter terrorism?}

So far the potential uses of informatics or data mining for counter terrorism purposes has been shown to apply to a number of use cases, these are:
\begin{enumerate}
\item Risk assessment. This can be either classification of a person as a terrorist or scoring risk for a person associated with them being a potential threat.
\item Generation of profiles. This involves the collection and collation of information on person providing this in an easy to digest format, providing simple self discovery tools to the user.
\item Discovery of networks. Link analysis, graph theory and graph visualization to allow discovery of terrorist networks.
\item Data collection and collation. This is the process of collection of data and data about that data (meta data) from disparate sources, cleaning the data, treatment of missing values and the storage of this data in readily available repository for querying by analysts.
\end{enumerate}

Each of these poses problems from a technical, moral and legal perspective. These problems are discussed below but can be restricted to the following areas:
\begin{enumerate}
\item The dangers of misuse of mass surveillance, to target, minorities, people of differing politic or religious persuasion.
\item The problem of class imbalance when building a predictive model of having relatively few samples to train on.
\item The related problem of the 'base rate fallacy' \citep{bar1980base}. This is common in a number of areas where the base rate of occurrences of what a statistical test or a machine learning algorithm is quite low, including fraud detection and intrusion detection \citep{axelsson2000base}.
\item The use of unsupervised methods where there is a very low frequency of a signal for terrorist behaviour.
\end{enumerate}

\subsection{The dangers of mass surveillance and its misuse}
While data mining can be an important counter terrorism tool its use especially when used in tandem with mass surveillance techniques is extremely effective and important for counter terrorism operations. However care must be taken when using such systems so as to guard against their misuse. There are many examples of these systems being misused in both democratic regimes and non democratic regimes. The misuse of mass surveillance techniques pre-date the digital computer. Examples of this would  be the attempted mass conscription of Norwegian males in WW2 by occupying German forces. On learning of the proposed plan Norwegian resistance fighters instead of destroying the files which were going to be used to base the conscription orders of the men, they destroyed the machines used to sort the data. Without the necessary information to aggregate the population data, a draft of the Norwegian populace was too difficult to instantiate without access to properly aggregated by age cohort data \citep{bignami2007european}. Abuses of these techniques are not just limited to totalitarian regimes but also to democratic ones. During the civil rights era in the US, the FBI frequently wire-tapped Dr. Martin Luther King with his colleagues in the civil rights movement \citep{garrow2015fbi}. The wire-taps were done to try and establish whether Dr. King had any ties with the Soviet Union. Other notable examples of this are the Lyndon Johnston administrations use of mass surveillance to investigate if any of Barry Goldwaters staff were homosexual's (for the purpose of discrediting them) during the 1964 presidential elections \citep{sales2014domesticating}.

\subsection{The problem of class imbalance in counter terrorism datamining} 
One of the criticisms of data mining (for terrorism or terrorist identification) is that very few training patterns exist in terrorism due to the relatively few cases of it. This low frequency of it occurring (or people perpetrating acts of terrorism) has made it very difficult to detect. When carrying out a classification type supervised data mining task to build a model, this problem is referred to as class imbalance \citep{SASClassimbalance2015}. If this problem is not extremely severe, certain actions which involve either sampling (over or under sampling of minority/majority class), algorithmic means (using algorithms that are less susceptible to class imbalance), using cost based classification techniques or using synthesized artificial minority classes as surrogates for the minority class can be used to treat the class imbalance. However if the class imbalance is very severe, the above methods will not be effective especially over/under sampling, which will only serve to train a model to identify specific examples \citep{jonas2006effective}.

\subsection{The problem of low base rates of terrorism in counter terrorism datamining}

This problem (of classification of terrorism) is exasperated by the fact even if you can train a model to accurately predict terrorist behaviour, the base rate of terrorism is so low the model may not be useful \citep{jensen2003information}. The base rate fallacy can be best explained with the following example. If the frequency of terrorists in a fictional city is very low, 100 terrorists in 1,000,000 people. Say if a system is built which has a true positive rate of 99\% (sensitivity, also referred to as the recall, this measures the proportion of positives are are rightly classified) and a true negative rate of 99\% (specificity, the proportions of negatives that are classified rightly) then in a city of 1,000,000 inhabitants where there are 100 terrorists. 99 out of 100 terrorists will will be classified correctly. Of the 999,900 of the non terrorists 9999 will be wrongly identified as terrorists. Therefore the detection rate will be approximately 99/(9999+99), which is  0.009803922 correctly identified as terrorists, this at best could function as a filter and at worst would either overwhelm the security apparatus of a state or a city with too many cases (due to the security services being overwhelmed of 'drowning' in false positives) to investigate. 

Bayes theorem states that:

\begin{equation} p(A|B)=P(B|A)P(A)/P(B) \label{eq1bayes}  \end{equation}

Where A and B are observed incidents, P(A) and P(A) are the probabilities of said events, and P(A$\vert$B) is a conditional probability of observing incident A given that B is true. P(B$\vert$A) is the conditional probability of observing incident B given that A is true. from this we can get the equation for terrorist events occurring  \label{eq2bayes}.
 
\begin{equation} p(terrorist|T)=p(T|terrorist)p(terrorist)/p(T) \label{eq2bayes}  \end{equation}

Where T means the algorithm indicates the person as a terrorist.

The base rate fallacy is not uncommon and exists in other fields, particularly in other related criminal investigation fields such as fraud detection. Other problems arise to do with data mining approaches to counter terrorism and may cause it to fail these include; bad data quality due to a myriad of reasons, missing data, misinterpreted field reports or inconsistent intelligence reports \citep{thuraisingham2004data}. 

\subsection{Low observable signal for terrorism and the use of unsupervised methods}

To overcome this difficulty data mining for terrorism has instead tried to detect anomalous information, but again anomalous behaviour may not be indicative of terrorist behaviour just behaviour which is outside the norm \citep{thuraisingham2004data}. Therefore if incorrectly used data mining can exacerbate a problem of trying to identify terrorists, however if used to support investigators in collating information acting as a filter to narrow down a list of suspects, data mining can be effective.

\section{Discussion}

Traditional intelligence gathering methodologies used by the intelligence services include  HUMINT, GEOINT, MASINT, SIGINT, TECHINT, FININT and CYBINT and OSINT. While all methodologies are of use in combating terrorism CYBINT and OSINT have received in particular alot of attention with mass intelligence gathering and the use of data mining techniques. 
The most notable example of this type of system would be terrorist informatics systems such as PRISM. Terrorism informatics is the use of both data analysis and data mining for the provision of actionable insights to intelligence specialists. Data analysis is very much different to data mining in the context of terrorism informatics, data mining is the extraction of hidden patterns algorithmically from databases, while data analysis involves the use of subject based or pattern based queries to extract information from databases. Subject based queries start from a specific entity of interest (a person, a vehicle) and expand out to related items based on this entity. While pattern based queries uses data-mining or SNA to uncover previously unseen patterns in the data. Both data analysis and data mining are a key components of terrorism informatics,  which is the science of management and analysis of data pertaining to terrorism related information to aid in the investigation and prevention of terrorism.

Terrorism informatics, while its use has only recently been popularized, its use goes back to at least the 1970’s.  The use of terrorism informatics is reviewed from 3 different perspectives, ranging from West Germany in the 1970’s, to Israeli and US uses of terrorism informatics currently. The West Germans were one of the first countries to use data analysis in the investigation of terrorism. 
The Dragnet system they developed was used to locate members of the Baader Meinhof terrorist group and disrupt their operations. The Dragnet system developed by the West German government was one of the first instances of the use of informatics to the mass surveillance of a population and involved collating personnel information about West German citizens . Then through the recursive use of pattern based queries they were able to identify a cohort of people who fitted the characteristics of members of the Baader Meinhof terrorist  organization. Through the targeting of these specific individuals and not through mass targeting of (left leaning) individuals, they were able to successfully pursue the Baader Meinhof organization without the use of a heavy handed counter terrorism response and without falling victim to one of the key tactics of terrorism, provocation (see section~\ref{sec:chap1strataimsterr} ).

The US has seen wide adoption of terrorist informatics particularly since the September the 11th attacks of 2001 and the resulting ‘war on terror’. The US has expanded the use of terror informatics from data collection and collation to data mining to extract useful patterns in the detection of terrorists. The US has used a plethora of tools and technologies to data mine large repositories of information held on citizens, the most famous of these being the NSA’s PRISM and TSA’s ATS. PRISM is the NSA’s mass surveillance system and the ATS is the the TIA’s flight screening system. While the ATS has had some success most notably in its detection of Rael Al-Banna, the use of PRISM has been more controversial. The use of PRISM is controversial for a number of reasons, these are its constitutionality \citep{park2013big} and equally important, its effectiveness. 

The dangers of mass surveillance is if used inappropriately is that it can be used not for its intended purpose (detection of terrorists), but for more nefarious uses such as targeting groups or people with different political or religous beliefs.  Cases like this are not just limited to just totalitarian regimes, but there are examples of these techniques being used wrongly in democratic states. Just as importantly is the effectiveness of terrorism informatics. The utility and effectiveness of PRISM has been questioned amongst many commentators, stating that the information provided by PRISM offers nothing over what could be provided by more traditional systems and investigative methods. One of the most difficult problems when applying data mining to terrorism and in particularly in use of classification for predicting someone as a suspect terrorist is the low base rate of terrorism and also the low instances of terrorists compared to normal innocent civilians (class imbalance). This results in a large number of false positives even for very accurate (data mining) models (used for the detection of terrorism or terrorists). This could end up with an analyst drowning in ‘false positives’ and such a system being useless or worse still exasperating the problem of detecting terrorism.  

Israel’s use of terrorist informatics is one of pragmatism. Israel’s use of terrorist informatics has seen wide adoption of terrorist informatics and particular the integration of IOT and and terrorist informatics to provide security analysts with large amounts of information from disparate sources in an easy to digest and analyse manner. It has also adopted data mining but it has not used it for problems which may over reach from a technical point of view (for instance the detection of terrorism due to the low base rate problem) its capabilities. Instead Israel has adopted data mining approaches which provide additional information to investigators by being able to extract further information to aid an investigation. An example of such a task would be the Israeli security services use of data mining to classify vehicles or armed individuals as potential threats for further analysis.

Both statistics and machine learning have also been applied to the study of terrorism. One of the first methodologies applied to the study of terrorism was SNA and they have been used to study particular (terrorist) groups (and their interdependencies and intra group relationships). One of the earliest studies being the study of the interaction between the KGB and the IRA undertaken in the 1980’s. More recently SNA has been applied to ‘new terrorism’ groups and cells or components within those groups. Particular incidents that have received a large amount of analysis are the September 11th 2001 attacks on the world trade centre and the Bali bombings of 2004. SNA offers a number of advantages to a researcher, as they allow the true representation of a terrorist network, allowing discovery of key actors within the group, channels of communication and the true structure of the network to be ascertained. This can also be useful from a counter terrorist perspective either during an active investigation or post-hoc. During an active investigation key actors can be possibly found and removed from a network causing disruption to the network. 

Post-hoc analysis is useful as it can provide investigators useful information regarding structures within groups. However as ‘new terrorism’ moves more towards employing stochastic terrorism methods it’s usefulness may become less important as no formal network exists. Instead only a deeply fragmented network may exist and people who carry out acts of terrorism only use the group as point of inspiration or use technical information disseminated by the terrorist group to plan their attack.

Supervised methods such as survival analysis has been applied to the study of terrorism through the use of electronic terrorist incident databases to allow the study of how terrorist groups persist. Survival analysis has been applied extensively to study the persistence and longevity of terrorist groups using regression methods. Through the use of survival analysis and data sourced partially from the GTD, researchers  \citep{young2014survival} were able to ascertain what attributes contribute to a groups longevity. Unsupervised methods have also seen widespread adoption in the study of terrorism. Clustering has been used to enhance the predictive power to which analysts can ascertain the location of terrorist events. By spatio-behavioural clustering, similar attacks together and using these past locations to help predict future attacks \citep{townsley2008space},\citep{brown2004spatial}.

HMM’s \citep{allanach2004detecting}  have also been widely applied to the study of longevity of terrorist groups by being used to model the activity of a terrorist groups, is to use it to model activity of a particular group. Similarly they also been used to model activity of groups and used to model large increases (spurts) in activity of these groups. 

\section{Conclusion}

Data mining has evolved as a powerful supplemental to traditional intelligence methods such as SIGINT and HUMINT and with newer intelligence methods as an enabler  such as cyber (CYBINT) and open source (OSINT) intelligence. 
Data mining has been used to study both its application to counter terrorism as well as its application to the study of terrorism itself. A number of different data mining types (supervised and unsupervised methods) have been applied to both the study of terrorism and counter terrorism. A related field to data mining for the study of terrorism is the field of terrorism informatics, which also encompasses the collation, collection and cleaning of data along with the presentation of the data in a simple to interact with manner. Terrorism informatics systems may be also required to ingest data from many disparate sources, for instance IOT banks of sensors or social media data.

Problems arise to applying data mining approaches to counter terrorism, bad data quality due to a myriad of reasons, missing data, misinterpreted field or inconsistent reports.
If incorrectly used data mining can cause more problems than it solves to predict terrorism or terrorists, for the following reasons:
\begin{itemize}
\item Rare occurrences and low base rates of terrorism make application of structured data mining techniques impossible to use for counter terrorism purposes of classifying terrorists or predicting where and when a terrorist incident.
\item Rare occurrence of acts and characteristics of each terrorist act which  makes the act unique, makes the application of data mining techniques difficult whether unstructured or structured and can be a waste of time as the signal for terrorism is very low.
\end{itemize}

US experience with PRISM and other TIA related projects have so far proven that mass surveillance when used in combination with data mining does not work or when it does work  can over burden an analyst with the amount of false positives it generates or else can cause legal issues or can be abused and misused. 
Big data technologies are not a panacea for the underlying problems of low base rates of terrorism and the massive class imbalance in terrorists/non-terrorists \citep{Masssurvelilancefail2015}. However data mining, if used as a a support to an analyst in a directed investigation and employed in a wider top down approach to counter terrorism (as the Israeli experience) utilising data mining and auto collection of data has shown to be an effective counter terrorist tool. US experience with mass surveillance technologies like PRISM has thought us that due to the underlying mathematics (Bayes rule and the base rate fallacy) \citep{schneier2015data} that accurate prediction of individual terrorists or terrorist incidents is extremely difficult, though detection of changes in behaviour such as an increase in intensity, change in attack vector, geo spatial trends or weapon type is possible and extremely valuable in identifying underlying trends. 

Data mining is an effective means to carry out research into terrorism especially after an incident has occurred. Of particular interest is SNA and graph theory and the use of unsupervised methods (Hidden Markov Models) to try to understand the behaviour of groups. Data mining has also been successful in the application of supervised techniques particularly variance autoregressive regression and time series analysis (modelling the effectiveness of interventions) along with survival analysis in the analysis of what factors effect the longevity of a terrorist group.  